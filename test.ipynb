{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3dacaad",
   "metadata": {},
   "source": [
    "# TESTING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a882bf52",
   "metadata": {},
   "source": [
    "Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f262d4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993481f9",
   "metadata": {},
   "source": [
    "Device Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0772baee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Suppress tokenizer warning\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# Detect device\n",
    "device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "torch.set_num_threads(16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b112c5",
   "metadata": {},
   "source": [
    "## Loading and preprocessing according to Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11131673",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test.tsv', sep='\\t')  # replace with your file name\n",
    "\n",
    "test_df['title'] = test_df['title'].astype(str).str.strip()\n",
    "test_df['subject'] = test_df['subject'].astype(str).str.strip()\n",
    "test_df['text'] = test_df['text'].astype(str).str.strip()\n",
    "\n",
    "test_df['content'] = test_df['title'] + ' ' + test_df['subject'] + ' ' + test_df['text']\n",
    "\n",
    "def clean_for_bert(text):\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.encode('ascii', 'ignore').decode()\n",
    "    text = text.lower()\n",
    "    return text.strip()\n",
    "\n",
    "test_df['content'] = test_df['content'].apply(clean_for_bert)\n",
    "\n",
    "test_texts = list(test_df['content'])\n",
    "test_labels = list(test_df['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29898e13",
   "metadata": {},
   "source": [
    "## Saving Tokenized text for fast retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa151aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pre-tokenized test data.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"saved_model\")\n",
    "\n",
    "encodings = tokenizer(\n",
    "    test_texts,\n",
    "    truncation=True,\n",
    "    padding=True,\n",
    "    max_length=512,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "torch.save({\n",
    "    'input_ids': encodings['input_ids'],\n",
    "    'attention_mask': encodings['attention_mask'],\n",
    "    'labels': torch.tensor(test_labels)\n",
    "}, \"test_tokenized.pt\")\n",
    "print(\"Saved pre-tokenized test data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d2218fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.load(\"test_tokenized.pt\")\n",
    "\n",
    "dataset = TensorDataset(data['input_ids'], data['attention_mask'], data['labels'])\n",
    "test_loader = DataLoader(dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1a06f7",
   "metadata": {},
   "source": [
    "## Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31b2e9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 259/259 [43:42<00:00, 10.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0000 | Test Accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(\"saved_model\").to(device)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "preds_test = []\n",
    "true_labels_test = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids, attention_mask, labels = [x.to(device) for x in batch]\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            labels=labels\n",
    "        )\n",
    "        logits = outputs.logits\n",
    "        loss = outputs.loss\n",
    "\n",
    "        test_loss += loss.item() * labels.size(0)\n",
    "\n",
    "        predictions = torch.argmax(logits, dim=-1)\n",
    "        preds_test.extend(predictions.cpu().numpy())\n",
    "        true_labels_test.extend(labels.cpu().numpy())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader.dataset)\n",
    "test_acc = accuracy_score(true_labels_test, preds_test)\n",
    "\n",
    "print(f\"Test Loss: {avg_test_loss:.4f} | Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "825315f4",
   "metadata": {},
   "source": [
    "## Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9925f2b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      4284\n",
      "           1       1.00      1.00      1.00      3983\n",
      "\n",
      "    accuracy                           1.00      8267\n",
      "   macro avg       1.00      1.00      1.00      8267\n",
      "weighted avg       1.00      1.00      1.00      8267\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(true_labels_test, preds_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
